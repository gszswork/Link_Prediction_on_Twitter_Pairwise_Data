{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nFeature_Engineer:\\n    1. 提取 train.txt 中所有的 Nodes 和 Edges 关系\\n    2. 利用上述关系生成 pos_data 和 neg_data （已经生成，直接读取)\\n    3. 利用（1）中生成的 Nodes 和 Edges 生成图\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Feature_Engineer:\n",
    "    1. 提取 train.txt 中所有的 Nodes 和 Edges 关系\n",
    "    2. 利用上述关系生成 pos_data 和 neg_data （已经生成，直接读取)\n",
    "    3. 利用（1）中生成的 Nodes 和 Edges 生成图\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "dirname = 'data/'\n",
    "def save_obj(obj, name ):\n",
    "    with open(dirname+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open( dirname + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/train.txt\", \"r\") as f:\n",
    "     train_data = f.readlines()\n",
    "Nodes = []\n",
    "Edges = []\n",
    "for i in range(len(train_data)):\n",
    "    #if i%100 == 0:\n",
    "        #print(i)\n",
    "    nodes_list = [int(n) for n in train_data[i].split()]\n",
    "    for node in nodes_list:\n",
    "        Nodes.append(node)\n",
    "    for node in nodes_list[1:]:\n",
    "        Edges.append((nodes_list[0],node))\n",
    "Nodes = set(Nodes)\n",
    "# 生成Nodes和Edges，直接从train.txt 读取就可以"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取pos_data 和 neg_data，已经在本地保存，可以直接读取\n",
    "\n",
    "pos_data = load_obj(\"pos_data\")\n",
    "neg_data = load_obj(\"neg_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes number:\t Edges number:\n",
      "4867136 \t 24004361 \n",
      "\n",
      "posdata_length:  negdata_length:\n",
      "24004361 \t 23999986 \n",
      "\n",
      "first 10 pieces of pos_data and neg_data:\n",
      "[[(540762, 1912140), 1], [(540762, 1537559), 1], [(540762, 3091331), 1], [(540762, 2757277), 1], [(540762, 3237295), 1], [(540762, 1070876), 1], [(540762, 4008078), 1], [(540762, 1824878), 1], [(540762, 1005927), 1], [(540762, 2703564), 1]] \n",
      "\n",
      "[[(3480985, 2887932), 0], [(3480985, 888056), 0], [(3480985, 1084524), 0], [(3480985, 2144717), 0], [(3480985, 353911), 0], [(3480985, 1329443), 0], [(3480985, 288458), 0], [(3480985, 2630047), 0], [(3480985, 3966258), 0], [(3480985, 453298), 0]]\n"
     ]
    }
   ],
   "source": [
    "# train.txt 文件已经读取， pos_data 和 neg_data 也已经读取\n",
    "print('Nodes number:\\t','Edges number:')\n",
    "print(len(Nodes), '\\t',len(Edges), '\\n')\n",
    "print('posdata_length: ', 'negdata_length:')\n",
    "print(len(pos_data),'\\t', len(neg_data), '\\n')\n",
    "\n",
    "print('first 10 pieces of pos_data and neg_data:')\n",
    "print(pos_data[:10],'\\n')\n",
    "print(neg_data[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph has been built!\n"
     ]
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "G.add_nodes_from(Nodes)\n",
    "G.add_edges_from(Edges)\n",
    "# Edges and Nodes are all from train.txt (pos_data)\n",
    "print('Graph has been built!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph has been saved\n"
     ]
    }
   ],
   "source": [
    "# 保存G对象到本地\n",
    "save_obj(G, 'graph')\n",
    "print('graph has been saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build hash set for Edges , hash set is more quick for calculating\n",
    "hash_edges = set(Edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "209 55\n"
     ]
    }
   ],
   "source": [
    "#print(Edges[:10])\n",
    "# let's try a test node:\n",
    "test_node = 3043\n",
    "test_neig = sorted(nx.all_neighbors(G, test_node))\n",
    "print(len(test_neig))\n",
    "\n",
    "num_in = 0\n",
    "num_out = 0\n",
    "for one_neig in test_neig:\n",
    "    if (3043, one_neig) in hash_edges:\n",
    "        num_out += 1\n",
    "    if (one_neig, 3043) in hash_edges:\n",
    "        num_in +=1\n",
    "print(num_in, num_out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "debug: 为什么所有的边都被保存为了inbound？\n",
    "\n",
    "solution:  代码从trian.txt中读取了Edges，错在“直接把Edges转化为hash set 然后判断(e, node)是否存在”\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "生成pre_features: pre_features 需要包含哪些特征？\n",
    "\n",
    "1. neighbors number \n",
    "2. log(nei_number)\n",
    "3. all_neighbors\n",
    "4. inbound\n",
    "5. inbound_num\n",
    "6. outbound\n",
    "7. outboud_num\n",
    "    \n",
    "'''\n",
    "pre_features = {}\n",
    "for i,node in enumerate(list(Nodes)):\n",
    "    #if i % 50000 == 0:\n",
    "        #print('progress:',100*i/4867136, '%')    # uncomment if u want progress info\n",
    "    num_neig = len(sorted(nx.all_neighbors(G, node)))                 # 1\n",
    "    log_neig = (1. / math.log(num_neig+1)) if num_neig != 0 else 0    # 2\n",
    "    neig = sorted(nx.all_neighbors(G, node))                          # 3\n",
    "    \n",
    "    inbound = []\n",
    "    outbound = []\n",
    "    for e in list(neig):\n",
    "        if (e,node) in hash_edges:\n",
    "            inbound.append(e)\n",
    "        if (node,e) in hash_edges:\n",
    "            outbound.append(e)\n",
    "    \n",
    "    pre_features[node] = [num_neig, log_neig, neig, inbound, len(inbound), outbound, len(outbound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(pre_features, 'pre_features_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Next we combine the pos_data and neg_data to one file:\n",
    "SBdata\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy\n",
    "import pandas\n",
    "\n",
    "obj_data_dir = \"../../data/\"\n",
    "def save_obj(obj, name ):\n",
    "    with open(obj_data_dir + name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(obj_data_dir + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "# load data\n",
    "#training_edges=load_obj('SBdata')\n",
    "\n",
    "if pos_data is None:\n",
    "    pos_data = load_obj(\"pos_data\")\n",
    "if neg_data is None:\n",
    "    neg_data = load_obj(\"neg_data\")\n",
    "\n",
    "pos = pos_data\n",
    "neg = neg_data\n",
    "\n",
    "print(len(pos))\n",
    "print(neg[1])\n",
    "\n",
    "filename = \"SBdata\"\n",
    "SBdata = []\n",
    "for element in pos:\n",
    "    SBdata.append(element)\n",
    "for element in neg:\n",
    "    SBdata.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(SBdata, 'SBdata')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
