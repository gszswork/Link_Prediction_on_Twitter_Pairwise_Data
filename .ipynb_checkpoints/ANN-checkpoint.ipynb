{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre\n",
    "data_dir = \"data/\"\n",
    "def save_obj(obj, name ):\n",
    "    with open( name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(data_dir + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "# Get the training_data_df\n",
    "training_data_df = load_obj(\"training_df_simplified_4w\")\n",
    "final_training_data_df = training_data_df.iloc[:,3:20]\n",
    "# 0.511756 0.028259\n",
    "# get the labeled data df\n",
    "final_labels_df = training_data_df.iloc[:,2]\n",
    "\n",
    "test_df = test_df.iloc[:,2:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    num_of_neighbours_source  num_of_in_neighbours_source  \\\n",
      "0                      170.0                         26.0   \n",
      "0                     5056.0                        525.0   \n",
      "0                   509690.0                       1530.0   \n",
      "0                   110105.0                       1642.0   \n",
      "0                   119327.0                       1514.0   \n",
      "..                       ...                          ...   \n",
      "0                     1525.0                        195.0   \n",
      "0                       34.0                         10.0   \n",
      "0                      245.0                         71.0   \n",
      "0                      637.0                        637.0   \n",
      "0                      629.0                         46.0   \n",
      "\n",
      "    num_of_out_neighbours_source  num_of_neighbours_sink  \\\n",
      "0                          155.0                    89.0   \n",
      "0                         4959.0                   516.0   \n",
      "0                       509445.0                     1.0   \n",
      "0                       110084.0                    51.0   \n",
      "0                       119306.0                  2256.0   \n",
      "..                           ...                     ...   \n",
      "0                         1521.0                   272.0   \n",
      "0                           29.0                    11.0   \n",
      "0                          195.0                    33.0   \n",
      "0                            0.0                   562.0   \n",
      "0                          608.0                    45.0   \n",
      "\n",
      "    num_of_in_neighbours_sink  num_of_out_neighbours_sink  \\\n",
      "0                        89.0                         0.0   \n",
      "0                       516.0                         0.0   \n",
      "0                         1.0                         0.0   \n",
      "0                        51.0                         0.0   \n",
      "0                       145.0                      2250.0   \n",
      "..                        ...                         ...   \n",
      "0                       272.0                         0.0   \n",
      "0                        11.0                         0.0   \n",
      "0                        33.0                         0.0   \n",
      "0                       562.0                         0.0   \n",
      "0                        45.0                         0.0   \n",
      "\n",
      "    num_of_neighbours_sum  num_of_in_neighbours_sum  \\\n",
      "0                   259.0                     115.0   \n",
      "0                  5572.0                    1041.0   \n",
      "0                509691.0                    1531.0   \n",
      "0                110156.0                    1693.0   \n",
      "0                121583.0                    1659.0   \n",
      "..                    ...                       ...   \n",
      "0                  1797.0                     467.0   \n",
      "0                    45.0                      21.0   \n",
      "0                   278.0                     104.0   \n",
      "0                  1199.0                    1199.0   \n",
      "0                   674.0                      91.0   \n",
      "\n",
      "    num_of_out_neighbours_sum  salton_similarity_score    cosine  \\\n",
      "0                       155.0                 0.660606  0.000595   \n",
      "0                      4959.0                 0.702756  0.000074   \n",
      "0                    509445.0                 0.000000  0.000000   \n",
      "0                    110084.0                 0.542590  0.000006   \n",
      "0                    121556.0                 0.748333  0.000003   \n",
      "..                        ...                      ...       ...   \n",
      "0                      1521.0                 0.675126  0.000140   \n",
      "0                        29.0                 0.000000  0.000000   \n",
      "0                       195.0                 0.575268  0.000247   \n",
      "0                         0.0                 0.000000  0.000028   \n",
      "0                       608.0                 0.494637  0.000035   \n",
      "\n",
      "    jaccard_coefficient  preferential_attachment  adamic_adar  \\\n",
      "0              0.036000                  15130.0     0.959233   \n",
      "0              0.035880                2608896.0    22.957478   \n",
      "0              0.000000                 509690.0     0.000000   \n",
      "0              0.000318                5615355.0     3.611917   \n",
      "0              0.006407              269201712.0   155.439073   \n",
      "..                  ...                      ...          ...   \n",
      "0              0.033353                 414800.0     6.372811   \n",
      "0              0.000000                    374.0     0.000000   \n",
      "0              0.007246                   8085.0     0.168176   \n",
      "0              0.008410                 357994.0     1.122084   \n",
      "0              0.001486                  28305.0     0.086279   \n",
      "\n",
      "    resource_allocation  \n",
      "0              0.002722  \n",
      "0              0.074754  \n",
      "0              0.000000  \n",
      "0              0.004534  \n",
      "0              8.645925  \n",
      "..                  ...  \n",
      "0              0.014317  \n",
      "0              0.000000  \n",
      "0              0.000026  \n",
      "0              0.002511  \n",
      "0              0.000009  \n",
      "\n",
      "[40000 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "print(final_training_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_training_data_df = rescale_min_max(final_training_data_df)\n",
    "X=final_training_data_df\n",
    "# count=0\n",
    "# get the data and label\n",
    "y=final_labels_df\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_t, X_test, y_t, y_test = train_test_split(X,y)\n",
    "x_train = X_t\n",
    "x_test = X_test\n",
    "y_train = y_t\n",
    "y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = np.random.random((1000, 20))\n",
    "# y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)\n",
    "# x_test = np.random.random((100, 20))\n",
    "# y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "import tensorflow as tf\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=15, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# 选择损失函数，优化器\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "    0.001,\n",
    "    #  \n",
    "    decay_steps = 1000,\n",
    "    decay_rate = 1,\n",
    "    staircase = False\n",
    ")\n",
    "def get_optimizer():\n",
    "    return tf.keras.optimizers.Adam(lr_schedule)\n",
    "opt = get_optimizer()\n",
    "model.compile(opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=200,\n",
    "          batch_size=32)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not DataFrame",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-ee5d00bd8fd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_data_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-be3e800ad07c>\u001b[0m in \u001b[0;36mload_obj\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not DataFrame"
     ]
    }
   ],
   "source": [
    "test_data_df = load_obj(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not DataFrame",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-1aad5b7ffe71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_data_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m     \u001b[0mmake\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0musing\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mjaccard\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mcoefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-be3e800ad07c>\u001b[0m in \u001b[0;36mload_obj\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not DataFrame"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def predict():\n",
    "    \"\"\"\n",
    "    make the prediction using the jaccard's coefficient\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    cnt=0\n",
    "    for row in tqdm(test_data_df.iterrows()):\n",
    "        row_df = pd.DataFrame(row[1]).T\n",
    "        single_result = model.predict(row_df)[0][0]\n",
    "        #print(model.predict(row_df)[0][0])\n",
    "        cnt+=1\n",
    "        result.append((cnt, single_result))\n",
    "    return result\n",
    "result = predict()\n",
    "\n",
    "# # save the result\n",
    "\n",
    "\n",
    "'''\n",
    "Description: get time\n",
    "Input: \n",
    "Output: time\n",
    "''' \n",
    "def nowtime():\n",
    "    return time.strftime(\"%Y%m%d-%H%M\", time.localtime())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Description: Save prediction result to files\n",
    "Input: (1) result\n",
    "       (2) filename\n",
    "Output: \n",
    "\"\"\"\n",
    "def save_prediction_to_csv(result,filename):\n",
    "    headers = ['id','Predicted']\n",
    "\n",
    "    with open(filename + str(nowtime()) + \".csv\", 'w', encoding = 'utf8') as f:\n",
    "        f_csv = csv.writer(f)\n",
    "        f_csv.writerow(headers)\n",
    "        f_csv.writerows(result)\n",
    "save_prediction_to_csv(result, \"shawn_ann_v1_200epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
